{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><body><p>test</p></body></html>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html><head></head><body><p>test</p></body></html>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'html5lib')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test</p>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = \"<p>test</p>\"\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title>나의 웹페이지</title></head>\n",
    "<p>test1</p>\n",
    "<p>test2</p>\n",
    "<p>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head><title>나의 웹페이지</title></head>\n",
       "<body><p>test1</p>\n",
       "<p>test2</p>\n",
       "<p>test3</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<body><p>test1</p>\n",
       "<p>test2</p>\n",
       "<p>test3</p>\n",
       "</body>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test1</p>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>나의 웹페이지</title></head>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>test1</p>, <p>test2</p>, <p>test3</p>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test1</p>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>test2</p>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title> test site </title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습\n",
    "* p 요소 전부 가져오기\n",
    "* span 요소 전부 가져오기\n",
    "* head 요소 전부 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test2</p>,\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"class3\">span tag text</span>]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<head><title> test site </title></head>]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"head\")    # find_all : 리스트 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\")          # find : 문자열 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"span\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title> test site </title></head>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"head\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * ESC + M : 마크다운 셀 만들기\n",
    " * ESC + Y : 소스코드 실행 셀 만들기\n",
    " * ESC + A : 위에 셀 추가\n",
    " * ESC + B : 아래 셀 추가\n",
    " * ESC + X : 셀 삭제\n",
    " * SHIFT + ENTER : 셀 실행 셀 추가 (다음 위치로)\n",
    " * CTRL + ENTER : 셀 실행(현재 위치에 그대로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "<html>\n",
    "<head><title> test site </title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> test site </title>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html, 'lxml')\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# class 이름으로 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", class_ = \"class1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id 이름으로 요소 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p id=\"p1\">오늘의 주가지수 1500</p>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(\"p\", id=\"p1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title> test site </title></head>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = soup.find(\"head\")\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title> test site </title>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = soup.find(\"title\")\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test site '"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<p id=\"p1\">오늘의 주가지수 1500</p>\n",
       "<p class=\"class4\">test3</p>\n",
       "<span class=\"class3\">span tag text</span>\n",
       "</div>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-2 (실습) div 2번째 요소 안의 p태그 전체를 가져와 보자.\n",
    "div2 = soup.find_all('div')[1]\n",
    "div2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p id=\"p1\">오늘의 주가지수 1500</p>, <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = div2.find_all(\"p\")\n",
    "p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-2 (추가) div 첫번째 요소의 안의 첫번째 p태그 요소 가져오기\n",
    "soup.find(\"div\").find(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p align=\"left\" class=\"class1\">test3</p>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.div.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <a href=\"https://www.google.com\">구글</a>\n",
    "    <div>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.com\n",
      "https://www.naver.com/\n",
      "https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "# 3-2 (생각해보기) a태그의 모든 url을 가져오기\n",
    "urls = soup.find_all(\"a\")\n",
    "\n",
    "for url in urls:\n",
    "#     print(url)\n",
    "    print(url.get(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'href': 'https://www.google.com'}\n",
      "https://www.google.com\n",
      "{'href': 'https://www.naver.com/'}\n",
      "https://www.naver.com/\n",
      "{'href': 'https://www.daum.com/'}\n",
      "https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "urls = soup.find_all(\"a\")\n",
    "\n",
    "for url in urls:\n",
    "    print(url.attrs)\n",
    "    print(url.attrs['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   test site\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p align=\"left\" class=\"class1\">\n",
      "   test3\n",
      "  </p>\n",
      "  <p class=\"class1\">\n",
      "   test2\n",
      "  </p>\n",
      "  <p id=\"p1\">\n",
      "   오늘의 주가지수 1500\n",
      "  </p>\n",
      "  <span class=\"class3\">\n",
      "   span tag text\n",
      "  </span>\n",
      "  <p class=\"class4\">\n",
      "   test3\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head><title> test site </title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "print( soup.prettify() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <a href=\"https://www.google.com\">구글</a>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup.find_all(\"div\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div>\n",
       "<a href=\"https://www.google.com\">구글</a>\n",
       "<p align=\"left\" class=\"class1\">test3</p>\n",
       "<p class=\"class1\">test2</p>\n",
       "</div>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1 = soup.find(\"div\")\n",
    "div1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<list_iterator at 0x2d12221a6d0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div1.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " <a href=\"https://www.google.com\">구글</a>,\n",
       " '\\n',\n",
       " <p align=\"left\" class=\"class1\">test3</p>,\n",
       " '\\n',\n",
       " <p class=\"class1\">test2</p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(div1.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <a href=\"https://www.google.com\">구글</a>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3-3 주어진 코드에서 children 속성을 이용해서 span 태그 요소를 가져와 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# div2 = soup.find_all(\"div\")[1]\n",
    "# div2.children\n",
    "\n",
    "div2 = soup.find_all(\"div\")[1]\n",
    "div2.children\n",
    "list(div2.children)\n",
    "div2_span=list(div2.children)[5]\n",
    "div2_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(div2.children)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"class3\">span tag text</span>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list( soup.find_all(\"div\")[1].children )[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = '''\n",
    "<html>\n",
    "<head>\n",
    "    <title> test site </title>\n",
    "</head>\n",
    "<body>\n",
    "    <div>\n",
    "        <a href=\"https://www.google.com\">구글</a>\n",
    "        <p class='class1' align=\"left\">test3</p>\n",
    "        <p class='class1'>test2</p>\n",
    "    </div>\n",
    "    <div>\n",
    "        <p id='p1'>오늘의 주가지수 1500</p>\n",
    "        <p class='class4'>test3</p>\n",
    "        <span class='class3'>span tag text</span>\n",
    "        <a href=\"https://www.naver.com/\">네이버</a>\n",
    "        <a href=\"https://www.daum.com/\">다음</a>\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "'''\n",
    "soup = BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " <p class=\"class1\">test2</p>,\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " <p class=\"class4\">test3</p>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4-2 p 태그의 text를 가져오기\n",
    "p_all = soup.find(\"body\").find_all(\"p\")\n",
    "p_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test3\n",
      "test2\n",
      "오늘의 주가지수 1500\n",
      "test3\n"
     ]
    }
   ],
   "source": [
    "for one in p_all :\n",
    "    print(one.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.google.com\">구글</a>,\n",
       " <a href=\"https://www.naver.com/\">네이버</a>,\n",
       " <a href=\"https://www.daum.com/\">다음</a>]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4-2 (추가) a태그의 url 및 text가져오기.\n",
    "url = soup.find(\"body\").find_all(\"a\")\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글\n",
      "네이버\n",
      "다음\n"
     ]
    }
   ],
   "source": [
    "for one in url:\n",
    "    print(one.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n"
     ]
    }
   ],
   "source": [
    "list_a = soup.findAll(\"a\")\n",
    "for one in list_a:\n",
    "    print(one.text, one.get(\"href\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-3 (실습) 위의 내용을 csv파일로 만들어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "구글 https://www.google.com\n",
      "네이버 https://www.naver.com/\n",
      "다음 https://www.daum.com/\n",
      "['구글', '네이버', '다음']\n",
      "['https://www.google.com', 'https://www.naver.com/', 'https://www.daum.com/']\n"
     ]
    }
   ],
   "source": [
    "com = []\n",
    "urls = []\n",
    "list_a = soup.findAll(\"a\")\n",
    "for one in list_a:\n",
    "    print(one.text, one.get(\"href\"))\n",
    "    com.append(one.text)\n",
    "    urls.append(one.get('href'))\n",
    "print(com)\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv파일 만들기 - pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas의 기본 자료형\n",
    " * Series\n",
    " * DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회사명</th>\n",
       "      <th>웹사이트</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>구글</td>\n",
       "      <td>https://www.google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>네이버</td>\n",
       "      <td>https://www.naver.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음</td>\n",
       "      <td>https://www.daum.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   회사명                    웹사이트\n",
       "0   구글  https://www.google.com\n",
       "1  네이버  https://www.naver.com/\n",
       "2   다음   https://www.daum.com/"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat= {'회사명':com, '웹사이트':urls}\n",
    "dat = pd.DataFrame(dat)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\Jupyter Notbook\\0616_project\n",
      "['.ipynb_checkpoints', '20210616.ipynb', '회사명과웹사이트.csv']\n"
     ]
    }
   ],
   "source": [
    "dat.to_csv(\"회사명과웹사이트.csv\", index=False)\n",
    "\n",
    "## 확인\n",
    "import os\n",
    "print( os.getcwd() )  # 현재 위치\n",
    "print( os.listdir(os.getcwd()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4 (추가) 링크 가져오기 (???? 모름)\n",
    "https://ldjwj.github.io/00_PYTHON_LEVELUP_CLASS/web_class/index.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>국내증시 : 네이버 금융</title>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "\n",
    "page = urlopen(url)\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3,278.68 998.49 436.96\n"
     ]
    }
   ],
   "source": [
    "kospi = soup.find(\"span\", id = \"KOSPI_now\").text\n",
    "kosdaq = soup.find(\"span\", id = \"KOSDAQ_now\").text\n",
    "kospi200 = soup.find(\"span\", id = \"KPI200_now\").text\n",
    "\n",
    "print(kospi, kosdaq, kospi200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 코스피 지수는 : 3,278.68\n",
      "현재 코스닥 지수는 : 998.49\n",
      "현재 코스피200 지수는 : 436.96\n"
     ]
    }
   ],
   "source": [
    "kosdaq = soup.find('span', id='KOSDAQ_now').text # 코스닥\n",
    "kospi = soup.find('span', id='KOSPI_now').text # 코스피\n",
    "kpi200 = soup.find('span', id='KPI200_now').text # 코스피200\n",
    "print(\"현재 코스피 지수는 :\", kospi)\n",
    "print(\"현재 코스닥 지수는 :\", kosdaq)\n",
    "print(\"현재 코스피200 지수는 :\", kpi200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 해당 정보가 있는 부분을 가져온다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<li><em>1.</em><a href=\"/item/main.nhn?code=005930\" onclick=\"clickcr(this,'boa.list','005930','1',event)\">삼성전자</a><span class=\"up\">81,800</span><em class=\"bu_p bu_pup\"><span class=\"blind\">상승</span></em></li>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_stock = soup.find(\"ul\", id = \"popularItemList\")\n",
    "stock_all = search_stock.find_all(\"li\")\n",
    "stock_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삼성전자\n",
      "81,800\n"
     ]
    }
   ],
   "source": [
    "print(stock_all[0].find(\"a\").text)\n",
    "print(stock_all[0].find(\"span\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_all = []\n",
    "price_all = []\n",
    "for one in stock_all:\n",
    "    com_one = one.find(\"a\").text\n",
    "    price_one = one.find(\"span\").text\n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['삼성전자', '카카오', '쌍방울', '두산중공업', '한전산업', '자연과환경', 'HMM', '대원전선', 'NAVER', '한국전력']\n",
      "['81,800', '143,000', '1,050', '24,450', '11,100', '2,780', '45,050', '3,555', '391,000', '26,700']\n"
     ]
    }
   ],
   "source": [
    "print(com_all)\n",
    "print(price_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>com</th>\n",
       "      <th>up_down</th>\n",
       "      <th>price</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>삼성전자</td>\n",
       "      <td>상승</td>\n",
       "      <td>81,800</td>\n",
       "      <td>005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>카카오</td>\n",
       "      <td>하락</td>\n",
       "      <td>143,000</td>\n",
       "      <td>035720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>쌍방울</td>\n",
       "      <td>하락</td>\n",
       "      <td>1,050</td>\n",
       "      <td>102280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>두산중공업</td>\n",
       "      <td>상승</td>\n",
       "      <td>24,450</td>\n",
       "      <td>034020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>한전산업</td>\n",
       "      <td>상한가</td>\n",
       "      <td>11,100</td>\n",
       "      <td>130660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>자연과환경</td>\n",
       "      <td>상한가</td>\n",
       "      <td>2,780</td>\n",
       "      <td>043910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>HMM</td>\n",
       "      <td>상승</td>\n",
       "      <td>45,050</td>\n",
       "      <td>011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>대원전선</td>\n",
       "      <td>상승</td>\n",
       "      <td>3,555</td>\n",
       "      <td>006340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>NAVER</td>\n",
       "      <td>상승</td>\n",
       "      <td>391,000</td>\n",
       "      <td>035420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>한국전력</td>\n",
       "      <td>상승</td>\n",
       "      <td>26,700</td>\n",
       "      <td>015760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  rank    com up_down    price    code\n",
       "0   1.   삼성전자      상승   81,800  005930\n",
       "1   2.    카카오      하락  143,000  035720\n",
       "2   3.    쌍방울      하락    1,050  102280\n",
       "3   4.  두산중공업      상승   24,450  034020\n",
       "4   5.   한전산업     상한가   11,100  130660\n",
       "5   6.  자연과환경     상한가    2,780  043910\n",
       "6   7.    HMM      상승   45,050  011200\n",
       "7   8.   대원전선      상승    3,555  006340\n",
       "8   9.  NAVER      상승  391,000  035420\n",
       "9  10.   한국전력      상승   26,700  015760"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## naver finance 인기 종목; 이응진\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "page\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "all_pop = soup.find(\"ul\", class_=\"lst_pop\").find_all(\"li\")\n",
    "all_data = []\n",
    "for li in all_pop:\n",
    "    dic = {}\n",
    "    dic[\"rank\"] = li.find(\"em\").text\n",
    "    dic[\"com\"] = li.find(\"a\").text\n",
    "    dic[\"up_down\"] = li.find('span', class_='blind').text\n",
    "    dic[\"price\"] = li.find('span').text\n",
    "    dic[\"code\"] = li.find('a').get(\"onclick\").split(',')[2].strip(\"''\")\n",
    "    all_data.append(dic)\n",
    "dat = pd.DataFrame(all_data)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.삼성전자81,800상승\n",
      "2.카카오143,000하락\n",
      "3.쌍방울1,050하락\n",
      "4.두산중공업24,450상승\n",
      "5.한전산업11,100상한가\n",
      "6.자연과환경2,780상한가\n",
      "7.HMM45,050상승\n",
      "8.대원전선3,555상승\n",
      "9.NAVER391,000상승\n",
      "10.한국전력26,700상승\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5-3 (추가) 인기 검색 종목 +(상승), -(하락) 포함시키기\n",
    "ul_= soup.findAll('ul',class_='lst_pop', id=\"popularItemList\")\n",
    "for x in ul_:\n",
    "    print(x.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 삼성전자 81,800\n",
      "2 카카오 143,000\n",
      "3 쌍방울 1,050\n",
      "4 두산중공업 24,450\n",
      "5 한전산업 11,100\n",
      "6 자연과환경 2,780\n",
      "7 HMM 45,050\n",
      "8 대원전선 3,555\n",
      "9 NAVER 391,000\n",
      "10 한국전력 26,700\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "data = requests.get('https://finance.naver.com/sise/')\n",
    "soup = BeautifulSoup(data.text, 'html.parser')\n",
    "likes = soup.select('#contentarea > div.box_top_submain2 > div.rgt> #popularItemList > li')\n",
    "rank = 1\n",
    "for like in likes:\n",
    "    a = like.select_one('a')\n",
    "    if a is not None:\n",
    "        title = a.text\n",
    "        updown = like.select_one('span').text\n",
    "        print(rank,title,updown)\n",
    "        rank += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.삼성전자81,800상승\n",
      "2.카카오143,000하락\n",
      "3.쌍방울1,050하락\n",
      "4.두산중공업24,450상승\n",
      "5.한전산업11,100상한가\n",
      "6.자연과환경2,780상한가\n",
      "7.HMM45,050상승\n",
      "8.대원전선3,555상승\n",
      "9.NAVER391,000상승\n",
      "10.한국전력26,700상승\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = \"https://finance.naver.com/sise/\"\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "rank_1 = soup.find('div', class_='rgt')\n",
    "rank_list = rank_1.find('ul').text.split('\\n')\n",
    "for i in rank_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['삼성전자', '카카오', '쌍방울', '두산중공업', '한전산업', '자연과환경', 'HMM', '대원전선', 'NAVER', '한국전력']\n",
      "['81,800', '143,000', '1,050', '24,450', '11,100', '2,780', '45,050', '3,555', '391,000', '26,700']\n",
      "['상승', '하락', '하락', '상승', '상한가', '상한가', '상승', '상승', '상승', '상승']\n",
      "[\"'005930'\", \"'035720'\", \"'102280'\", \"'034020'\", \"'130660'\", \"'043910'\", \"'011200'\", \"'006340'\", \"'035420'\", \"'015760'\"]\n"
     ]
    }
   ],
   "source": [
    "# 5-3 (추가) 인기 검색 종목 코드 가져오기\n",
    "search_stock=soup.find('ul',id='popularItemList')\n",
    "stock_all=search_stock.find_all('li')\n",
    "com_all=[]\n",
    "price_all=[]\n",
    "rank_all=[]\n",
    "code_all=[]\n",
    "for one in stock_all:\n",
    "    com_one=one.find('a').text\n",
    "    price_one=one.find('span').text\n",
    "    rank_one=one.find('span',class_='blind').text\n",
    "    code_one=one.find('a').get(\"onclick\").split(',')[2]\n",
    "    com_all.append(com_one)\n",
    "    price_all.append(price_one)\n",
    "    rank_all.append(rank_one)\n",
    "    code_all.append(code_one)\n",
    "print(com_all)\n",
    "print(price_all)\n",
    "print(rank_all)\n",
    "print(code_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-3 (도전) 주요 해외 지수 가져오기"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
